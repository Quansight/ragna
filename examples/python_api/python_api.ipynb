{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d1b9f01-ae07-488e-b3d2-62d01ad828c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "assert load_dotenv(\"../../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3e91c88-13ca-417e-8205-9ef3b16f0d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.dev29+g03721c7.d20231009084220'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ragna\n",
    "\n",
    "ragna.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a3759a6-ffb0-47f7-be40-cf9d62fc67da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(local_cache_root=PosixPath('/home/philip/.cache/ragna'), state_database_url='sqlite://', queue_database_url='memory', ragna_api_url='http://127.0.0.1:31476', ragna_ui_url='http://127.0.0.1:31477', document_class=<class 'ragna.core.LocalDocument'>, upload_token_secret='16d97e7eb82eaa866805280bf3e4302b8d459fa70e1c77753fdaa8ad047fa55f', upload_token_ttl=30, registered_source_storage_classes={'Ragna/DemoSourceStorage': <class 'ragna.source_storage._demo.RagnaDemoSourceStorage'>}, registered_assistant_classes={'Ragna/DemoAssistant': <class 'ragna.assistant._demo.RagnaDemoAssistant'>})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragna import demo_config, Config\n",
    "\n",
    "demo_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87613cac-44ba-4b85-ad3e-a1127dd65aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_path = \"demo_document.txt\"\n",
    "\n",
    "with open(document_path, \"w\") as file:\n",
    "    file.write(\"Ragna is an open-source RAG orchestration app\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "818ff37c-d693-44b2-9d56-104eb2d86f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can't really help you with your prompt:\n",
      "\n",
      "> What is Ragna?\n",
      "\n",
      "I can at least show you the sources that I was given:\n",
      "\n",
      "- demo_document.txt: Ragna is an open-source RAG orchestration app\n"
     ]
    }
   ],
   "source": [
    "from ragna.core import Rag\n",
    "from ragna.assistant import (\n",
    "    RagnaDemoAssistant,\n",
    "    OpenaiGpt35Turbo16kAssistant,\n",
    "    OpenaiGpt4Assistant,\n",
    ")\n",
    "from ragna.source_storage import (\n",
    "    ChromaSourceStorage,\n",
    "    RagnaDemoSourceStorage,\n",
    "    LanceDBSourceStorage,\n",
    ")\n",
    "\n",
    "rag = Rag(demo_config)\n",
    "\n",
    "async with rag.chat(\n",
    "    documents=[document_path],\n",
    "    source_storage=RagnaDemoSourceStorage,\n",
    "    assistant=RagnaDemoAssistant,\n",
    ") as chat:\n",
    "    prompt = \"What is Ragna?\"\n",
    "    answer = await chat.answer(prompt)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c2f04c8-a0e1-47fc-a900-bc03b91088a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('Chroma', 'OpenAI/gpt-3.5-turbo-16k'): <coroutine object answer_prompt at 0x7ff6b6164ac0>,\n",
      " ('Chroma', 'OpenAI/gpt-4'): <coroutine object answer_prompt at 0x7ff6b6164b40>,\n",
      " ('LanceDB', 'OpenAI/gpt-3.5-turbo-16k'): <coroutine object answer_prompt at 0x7ff6b6164bc0>,\n",
      " ('LanceDB', 'OpenAI/gpt-4'): <coroutine object answer_prompt at 0x7ff6b6164c40>}\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import asyncio\n",
    "from pprint import pprint\n",
    "\n",
    "source_storages = [ChromaSourceStorage, LanceDBSourceStorage]\n",
    "assistants = [OpenaiGpt35Turbo16kAssistant, OpenaiGpt4Assistant]\n",
    "\n",
    "\n",
    "async def answer_prompt(source_storage, assistant):\n",
    "    async with rag.chat(\n",
    "        documents=[document_path],\n",
    "        source_storage=source_storage,\n",
    "        assistant=assistant,\n",
    "    ) as chat:\n",
    "        return await chat.answer(prompt)\n",
    "\n",
    "\n",
    "experiments = {\n",
    "    (source_storage.display_name(), assistant.display_name()): answer_prompt(\n",
    "        source_storage, assistant\n",
    "    )\n",
    "    for source_storage, assistant in itertools.product(source_storages, assistants)\n",
    "}\n",
    "\n",
    "pprint(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d125a99d-51c2-4008-b49b-0c648abdb9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "{('Chroma', 'OpenAI/gpt-3.5-turbo-16k'): Message(content='Ragna is an open-source RAG (Response Analysis Graph) orchestration app. It is designed to help users create conversational AI applications by providing a framework for managing and orchestrating the flow of conversations. Ragna allows developers to define conversation flows, handle user inputs, and generate dynamic responses based on predefined rules and logic. It is built on top of the Rasa framework and provides additional features and functionalities to simplify the development process.', role=<MessageRole.ASSISTANT: 'assistant'>, sources=[Source(id='4afc4718-c8b0-4d3b-b103-24ecfce42a99', document=<ragna.core.LocalDocument object at 0x7ff6b406a640>, location='', content='Ragna is an open-source RAG orchestration app\\n', num_tokens=12)]),\n",
      " ('Chroma', 'OpenAI/gpt-4'): Message(content='Ragna is an open-source RAG orchestration app.', role=<MessageRole.ASSISTANT: 'assistant'>, sources=[Source(id='519efd9e-a464-4261-8589-30f7be716b6a', document=<ragna.core.LocalDocument object at 0x7ff6aff5e190>, location='', content='Ragna is an open-source RAG orchestration app\\n', num_tokens=12)]),\n",
      " ('LanceDB', 'OpenAI/gpt-3.5-turbo-16k'): Message(content='Ragna is an open-source rag orchestration app. It is a software application that allows users to create and arrange musical compositions using ragtime music. It is designed to be accessible and customizable for musicians and composers.', role=<MessageRole.ASSISTANT: 'assistant'>, sources=[Source(id='882b2ec7-2c63-44c8-8633-ce9b012869c5', document=<ragna.core.LocalDocument object at 0x7ff46c233910>, location='', content='[CLS] ragna is an open-source rag orchestration app[SEP]', num_tokens=12)]),\n",
      " ('LanceDB', 'OpenAI/gpt-4'): Message(content='Ragna is an open-source rag orchestration app.', role=<MessageRole.ASSISTANT: 'assistant'>, sources=[Source(id='693d2edb-4925-40f7-b25e-d5ed686670a5', document=<ragna.core.LocalDocument object at 0x7ff46b7389d0>, location='', content='[CLS] ragna is an open-source rag orchestration app[SEP]', num_tokens=12)])}\n"
     ]
    }
   ],
   "source": [
    "results = dict(zip(experiments.keys(), await asyncio.gather(*experiments.values())))\n",
    "pprint(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
