{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d1b9f01-ae07-488e-b3d2-62d01ad828c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "assert load_dotenv(\"../../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3e91c88-13ca-417e-8205-9ef3b16f0d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.dev21+g7f8ec2d.d20230925071852'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ragna\n",
    "\n",
    "ragna.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a3759a6-ffb0-47f7-be40-cf9d62fc67da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(local_cache_root=PosixPath('/home/philip/.cache/ragna'), state_database_url='sqlite://', queue_database_url='memory', ragna_api_url='http://127.0.0.1:31476', ragna_ui_url='http://127.0.0.1:31477', document_class=<class 'ragna.core.LocalDocument'>, upload_token_secret='245be1b4c5656eefec1ac16d4a856f189e9e35d35aa014eb7426573e5b86c03f', upload_token_ttl=30, registered_source_storage_classes={'Ragna/DemoSourceStorage': <class 'ragna.source_storage._demo.RagnaDemoSourceStorage'>}, registered_assistant_classes={'Ragna/DemoAssistant': <class 'ragna.assistant._demo.RagnaDemoAssistant'>})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragna import demo_config, Config\n",
    "\n",
    "demo_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87613cac-44ba-4b85-ad3e-a1127dd65aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_path = \"demo_document.txt\"\n",
    "\n",
    "with open(document_path, \"w\") as file:\n",
    "    file.write(\"Ragna is an open-source RAG orchestration app\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "818ff37c-d693-44b2-9d56-104eb2d86f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can't really help you with your prompt:\n",
      "\n",
      "> What is Ragna?\n",
      "\n",
      "I can at least show you the sources that I was given:\n",
      "\n",
      "- demo_document.txt: Ragna is an open-source RAG orchestration app\n"
     ]
    }
   ],
   "source": [
    "from ragna.core import Rag\n",
    "from ragna.assistant import (\n",
    "    RagnaDemoAssistant,\n",
    "    OpenaiGpt35Turbo16kAssistant,\n",
    "    OpenaiGpt4Assistant,\n",
    ")\n",
    "from ragna.source_storage import ChromaSourceStorage, RagnaDemoSourceStorage\n",
    "\n",
    "rag = Rag(demo_config)\n",
    "\n",
    "async with await rag.new_chat(\n",
    "    documents=[document_path],\n",
    "    source_storage=RagnaDemoSourceStorage,\n",
    "    assistant=RagnaDemoAssistant,\n",
    ") as chat:\n",
    "    prompt = \"What is Ragna?\"\n",
    "    answer = await chat.answer(prompt)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c2f04c8-a0e1-47fc-a900-bc03b91088a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('Chroma', 'OpenAI/gpt-3.5-turbo-16k'): <coroutine object answer_prompt at 0x7f73bfd15f40>,\n",
      " ('Chroma', 'OpenAI/gpt-4'): <coroutine object answer_prompt at 0x7f740774a040>}\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import asyncio\n",
    "from pprint import pprint\n",
    "\n",
    "source_storages = [ChromaSourceStorage]\n",
    "assistants = [OpenaiGpt35Turbo16kAssistant, OpenaiGpt4Assistant]\n",
    "\n",
    "\n",
    "async def answer_prompt(source_storage, assistant):\n",
    "    chat = await rag.new_chat(\n",
    "        documents=[document_path],\n",
    "        source_storage=source_storage,\n",
    "        assistant=assistant,\n",
    "    )\n",
    "    await chat.start()\n",
    "    return await chat.answer(prompt)\n",
    "\n",
    "\n",
    "experiments = {\n",
    "    (source_storage.display_name(), assistant.display_name()): answer_prompt(\n",
    "        source_storage, assistant\n",
    "    )\n",
    "    for source_storage, assistant in itertools.product(source_storages, assistants)\n",
    "}\n",
    "\n",
    "pprint(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d125a99d-51c2-4008-b49b-0c648abdb9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('Chroma', 'OpenAI/gpt-3.5-turbo-16k'): Ragna is an open-source RAG (Response Analysis Graph) orchestration app. It is designed to help users create conversational AI applications by providing a framework for managing and orchestrating the flow of conversations. Ragna allows developers to define conversation flows, handle user inputs, and generate dynamic responses based on predefined rules and logic. It is built on top of the Rasa framework and provides additional features and functionalities to simplify the development process.,\n",
      " ('Chroma', 'OpenAI/gpt-4'): Ragna is an open-source RAG orchestration app.}\n"
     ]
    }
   ],
   "source": [
    "results = dict(zip(experiments.keys(), await asyncio.gather(*experiments.values())))\n",
    "pprint(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
