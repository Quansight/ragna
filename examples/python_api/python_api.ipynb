{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e675a59d-f656-41f9-828a-912fd0e176ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _is_notebook():\n",
    "    try:\n",
    "        from IPython import get_ipython\n",
    "\n",
    "        return \"IPKernelApp\" in get_ipython().config\n",
    "    except Exception:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d1b9f01-ae07-488e-b3d2-62d01ad828c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "assert load_dotenv(\"../../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3e91c88-13ca-417e-8205-9ef3b16f0d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.dev16+ga4d3603.d20230914143851'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ragna\n",
    "\n",
    "ragna.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a3759a6-ffb0-47f7-be40-cf9d62fc67da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(state_database_url='sqlite://', queue_database_url='redis://127.0.0.1:6379', ragna_api_url='http://127.0.0.1:31476', ragna_ui_url='http://127.0.0.1:31477', local_cache_root=PosixPath('/home/philip/.cache/ragna'), document_class=<class 'ragna.core.LocalDocument'>, upload_token_secret='9e6020416528a671c3057800c6ce4452b6f77e9b29f62647fa9a8fb855065f54', upload_token_ttl=30, registered_source_storage_classes={'Ragna/DemoSourceStorage': <class 'ragna.source_storage._demo.RagnaDemoSourceStorage'>}, registered_assistant_classes={'Ragna/DemoAssistant': <class 'ragna.assistant._demo.RagnaDemoAssistant'>})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragna import demo_config, Config\n",
    "\n",
    "demo_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87613cac-44ba-4b85-ad3e-a1127dd65aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_path = \"demo_document.txt\"\n",
    "\n",
    "with open(document_path, \"w\") as file:\n",
    "    file.write(\"Ragna is an open-source RAG orchestration app\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "818ff37c-d693-44b2-9d56-104eb2d86f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"event\": \"Started ragna worker\", \"timestamp\": \"2023-09-20T19:14:01.928952Z\", \"level\": \"info\"}\n",
      "Ragna is an open-source RAG orchestration app. It is designed to help users create and manage RAG (Red, Amber, Green) status reports. Ragna allows users to easily track and communicate the status of various projects or tasks using a simple color-coded system. It provides a user-friendly interface for creating and updating RAG reports, as well as generating visualizations and reports based on the data entered. Ragna is built on open-source technologies and is available for free to use and customize.\n"
     ]
    }
   ],
   "source": [
    "from ragna.core import Rag\n",
    "from ragna.assistant import (\n",
    "    RagnaDemoAssistant,\n",
    "    OpenaiGpt35Turbo16kAssistant,\n",
    "    OpenaiGpt4Assistant,\n",
    ")\n",
    "from ragna.source_storage import ChromaSourceStorage, RagnaDemoSourceStorage\n",
    "\n",
    "rag = Rag(demo_config)\n",
    "\n",
    "async with await rag.new_chat(\n",
    "    documents=[document_path],\n",
    "    source_storage=RagnaDemoSourceStorage,\n",
    "    assistant=OpenaiGpt35Turbo16kAssistant,\n",
    ") as chat:\n",
    "    prompt = \"What is Ragna?\"\n",
    "    answer = await chat.answer(prompt)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c2f04c8-a0e1-47fc-a900-bc03b91088a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('Chroma', 'OpenAI/gpt-3.5-turbo-16k'): <coroutine object answer_prompt at 0x7f151a0e7240>,\n",
      " ('Chroma', 'OpenAI/gpt-4'): <coroutine object answer_prompt at 0x7f151a0e7440>}\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import asyncio\n",
    "from pprint import pprint\n",
    "\n",
    "source_storages = [ChromaSourceStorage]\n",
    "assistants = [OpenaiGpt35Turbo16kAssistant, OpenaiGpt4Assistant]\n",
    "\n",
    "\n",
    "async def answer_prompt(source_storage, assistant):\n",
    "    chat = await rag.new_chat(\n",
    "        documents=[document_path],\n",
    "        source_storage=source_storage,\n",
    "        assistant=assistant,\n",
    "    )\n",
    "    await chat.start()\n",
    "    return await chat.answer(prompt)\n",
    "\n",
    "\n",
    "experiments = {\n",
    "    (source_storage.display_name(), assistant.display_name()): answer_prompt(\n",
    "        source_storage, assistant\n",
    "    )\n",
    "    for source_storage, assistant in itertools.product(source_storages, assistants)\n",
    "}\n",
    "\n",
    "pprint(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d125a99d-51c2-4008-b49b-0c648abdb9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('Chroma', 'OpenAI/gpt-3.5-turbo-16k'): Ragna is an open-source RAG (Response Analysis Graph) orchestration app. It is designed to help users create conversational AI applications by providing a framework for managing and orchestrating the flow of conversations. Ragna allows developers to define conversation flows, handle user inputs, and generate dynamic responses based on predefined rules and logic. It is built on top of the Rasa framework and provides additional features and functionalities to simplify the development process.,\n",
      " ('Chroma', 'OpenAI/gpt-4'): Ragna is an open-source RAG orchestration app.}\n"
     ]
    }
   ],
   "source": [
    "results = dict(zip(experiments.keys(), await asyncio.gather(*experiments.values())))\n",
    "pprint(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
