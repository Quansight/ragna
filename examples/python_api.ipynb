{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d1b9f01-ae07-488e-b3d2-62d01ad828c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "assert load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3e91c88-13ca-417e-8205-9ef3b16f0d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.dev17+gfcf7439'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ragna\n",
    "\n",
    "ragna.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a3759a6-ffb0-47f7-be40-cf9d62fc67da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(local_cache_root=PosixPath('/home/philip/.cache/ragna'), state_database_url='sqlite:////home/philip/.cache/ragna/ragna.db', queue_database_url='redis://127.0.0.1:6379', registered_source_storage_classes={'Ragna/DemoSourceStorage': <class 'ragna.source_storage._demo.RagnaDemoSourceStorage'>}, registered_llm_classes={'Ragna/DemoLLM': <class 'ragna.llm._demo.RagnaDemoLlm'>})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragna import demo_config, Config\n",
    "\n",
    "demo_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87613cac-44ba-4b85-ad3e-a1127dd65aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_path = \"demo_document.txt\"\n",
    "\n",
    "with open(document_path, \"w\") as file:\n",
    "    file.write(\"Ragna is an open-source RAG orchestration app\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "818ff37c-d693-44b2-9d56-104eb2d86f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ragna is an open-source RAG orchestration app. It is designed to help users manage and automate their RAG (Red, Amber, Green) status reporting process. Ragna allows users to easily track and update the status of various tasks or projects, and provides a visual representation of the overall progress. It is a useful tool for teams or individuals who need to regularly report on the status of their work.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragna.core import Rag\n",
    "from ragna.llm import RagnaDemoLlm\n",
    "from ragna.source_storage import RagnaDemoSourceStorage\n",
    "from ragna.llm import OpenaiGpt35Turbo16kLlm, OpenaiGpt4Llm\n",
    "from ragna.source_storage import ChromaSourceStorage\n",
    "\n",
    "rag = Rag(demo_config, start_ragna_worker=4)\n",
    "\n",
    "chat = await rag.start_new_chat(\n",
    "    documents=[document_path],\n",
    "    source_storage=ChromaSourceStorage,\n",
    "    llm=OpenaiGpt35Turbo16kLlm,\n",
    ")\n",
    "\n",
    "prompt = \"What is Ragna?\"\n",
    "await chat.answer(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c2f04c8-a0e1-47fc-a900-bc03b91088a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('Chroma', 'OpenAI/gpt-3.5-turbo-16k'): <coroutine object answer_prompt at 0x7f22e1557740>,\n",
      " ('Chroma', 'OpenAI/gpt-4'): <coroutine object answer_prompt at 0x7f22e15576c0>}\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import asyncio\n",
    "from pprint import pprint\n",
    "\n",
    "from ragna.llm import OpenaiGpt35Turbo16kLlm, OpenaiGpt4Llm\n",
    "from ragna.source_storage import ChromaSourceStorage\n",
    "\n",
    "source_storages = [ChromaSourceStorage]\n",
    "llms = [OpenaiGpt35Turbo16kLlm, OpenaiGpt4Llm]\n",
    "\n",
    "\n",
    "async def answer_prompt(source_storage, llm):\n",
    "    chat = await rag.start_new_chat(\n",
    "        documents=[document_path],\n",
    "        source_storage=source_storage,\n",
    "        llm=llm,\n",
    "    )\n",
    "    return await chat.answer(prompt)\n",
    "\n",
    "\n",
    "experiments = {\n",
    "    (source_storage.display_name(), llm.display_name()): answer_prompt(\n",
    "        source_storage, llm\n",
    "    )\n",
    "    for source_storage, llm in itertools.product(source_storages, llms)\n",
    "}\n",
    "\n",
    "pprint(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d125a99d-51c2-4008-b49b-0c648abdb9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 2/2 [00:07<00:00,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('Chroma', 'OpenAI/gpt-3.5-turbo-16k'): 'Ragna is an open-source RAG '\n",
      "                                         'orchestration app. It is designed to '\n",
      "                                         'help users manage and automate their '\n",
      "                                         'RAG (Red, Amber, Green) status '\n",
      "                                         'reporting process. Ragna allows '\n",
      "                                         'users to easily track and update the '\n",
      "                                         'status of various tasks or projects, '\n",
      "                                         'and provides a visual representation '\n",
      "                                         'of the overall progress. It is a '\n",
      "                                         'useful tool for teams or individuals '\n",
      "                                         'who need to regularly report on the '\n",
      "                                         'status of their work.',\n",
      " ('Chroma', 'OpenAI/gpt-4'): 'Ragna is an open-source RAG (Retrieve and '\n",
      "                             \"Generate) orchestration app. It's a tool that \"\n",
      "                             'helps manage and coordinate the process of '\n",
      "                             'retrieving and generating data. Being '\n",
      "                             'open-source, it allows developers to modify and '\n",
      "                             'distribute the software to meet their specific '\n",
      "                             'needs.'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.asyncio import tqdm\n",
    "\n",
    "results = dict(zip(experiments.keys(), await tqdm.gather(*experiments.values())))\n",
    "\n",
    "pprint(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
