{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a30597e-681e-40cb-a414-31926893b9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://127.0.0.1:31476'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragna import demo_config\n",
    "\n",
    "URL = demo_config.ragna_api_url\n",
    "USER = \"Ragna\"\n",
    "\n",
    "URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f335a3-b143-4f8c-bcfd-31f992880464",
   "metadata": {},
   "source": [
    "We start the REST API in the background and wait for it to come up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f6e29a8-0bc0-4988-8e30-7da332d21f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"event\": \"Started ragna worker\", \"timestamp\": \"2023-09-20T19:14:35.258880Z\", \"level\": \"info\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [56010]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:31476 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:38984 - \"GET /health HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "import httpx\n",
    "\n",
    "proc = subprocess.Popen([\"ragna\", \"api\", \"--config\", \"ragna.demo_config\"])\n",
    "\n",
    "client = httpx.AsyncClient()\n",
    "\n",
    "timeout = 10\n",
    "start = time.time()\n",
    "while (time.time() - start) < timeout:\n",
    "    with contextlib.suppress(httpx.ConnectError):\n",
    "        response = await client.get(f\"{URL}/health\")\n",
    "        if response.is_success:\n",
    "            break\n",
    "\n",
    "    time.sleep(0.5)\n",
    "else:\n",
    "    proc.kill()\n",
    "    stdout, stderr = proc.communicate()\n",
    "    print(stdout)\n",
    "    print(stderr)\n",
    "    raise RuntimeError(\"Unable to start the Ragna REST API\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ad4c83-34a8-435f-b606-1e415fc8adb5",
   "metadata": {},
   "source": [
    "A user will have some documents that they want to interogate. Let's create some"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b9f694a-dc07-40e0-8a89-ee26456eae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "paths = []\n",
    "for i in range(3):\n",
    "    path = Path.cwd() / f\"document{i}.txt\"\n",
    "    with open(path, \"w\") as file:\n",
    "        file.write(f\"This is content of document {i}\\n\")\n",
    "    paths.append(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8645f0d-0f4e-4853-8740-6772f4ed4307",
   "metadata": {},
   "source": [
    "Before we start the Rag use case, let's make sure the "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef26a9a-0ee5-4bd5-87ab-e1b90de520f9",
   "metadata": {},
   "source": [
    "We start off by listing all the chats that our user has available. Inside a UI that would happen after login. Since the demo config we used above keeps the state in memory only, unsurprisingly, there are no available chats yets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14f7a094-3687-4027-8b69-b00533741a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:38984 - \"GET /chats?user=Ragna HTTP/1.1\" 200 OK\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "response = await client.get(f\"{URL}/chats\", params={\"user\": USER})\n",
    "pprint(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e3e6e1-1284-4ef0-975a-b8919a8f4df6",
   "metadata": {},
   "source": [
    "Let's check what RAG components are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9126cc0f-2a05-4088-9b98-d281bc5fa4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:38984 - \"GET /components?user=Ragna HTTP/1.1\" 200 OK\n",
      "{'assistants': ['Ragna/DemoAssistant'],\n",
      " 'source_storages': ['Ragna/DemoSourceStorage']}\n"
     ]
    }
   ],
   "source": [
    "response = await client.get(f\"{URL}/components\", params={\"user\": USER})\n",
    "components = response.json()\n",
    "pprint(components)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6d253c-54fa-4a9b-bc5b-17d2dc9969f5",
   "metadata": {},
   "source": [
    "We pick the demo components for the remainder of this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2635a44-48a2-49dc-80a6-e6d365f1cfd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Ragna/DemoSourceStorage', 'Ragna/DemoAssistant')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SOURCE_STORAGE = components[\"source_storages\"][0]\n",
    "ASSISTANT = components[\"assistants\"][0]\n",
    "\n",
    "SOURCE_STORAGE, ASSISTANT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaa4c94-4ef0-4be5-b350-069ad5691fcf",
   "metadata": {},
   "source": [
    "The document upload is a two-step process. First we request upload info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70e78762-4f6e-45d1-b1ef-38e5403679f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:38984 - \"GET /document/new?user=Ragna&name=document0.txt HTTP/1.1\" 200 OK\n",
      "{'data': {'token': 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyIjoiUmFnbmEiLCJpZCI6ImM4ZGE2MWNjLTA5MzMtNDNlNi05NjVlLWViZGY5ODFmZTk0YiIsImV4cCI6MTY5NTIzNzMwNS45MjQwNDc1fQ.moZJIXRmLO92SvpC3nC8gstFqL-rrnINljyaiIArLLc'},\n",
      " 'document': {'id': 'c8da61cc-0933-43e6-965e-ebdf981fe94b',\n",
      "              'name': 'document0.txt'},\n",
      " 'url': 'http://127.0.0.1:31476/document/upload'}\n"
     ]
    }
   ],
   "source": [
    "path = paths[0]\n",
    "\n",
    "response = await client.get(\n",
    "    f\"{URL}/document/new\", params={\"user\": USER, \"name\": path.name}\n",
    ")\n",
    "document_info = response.json()\n",
    "document = document_info[\"document\"]\n",
    "pprint(document_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea79e9bc-ea91-48ac-a68f-64e27ed2f09d",
   "metadata": {},
   "source": [
    "And use this info to perform the actual upload. While this seems unneccessarily complicated here, this is needed to support workflows when we want to upload directly to AWS S3 with presigned URLs. Note that the `token` has a short TTL. By default that is 30 seconds, but is configurable by `Config(upload_token_ttl=...)` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b43b943b-47a8-46a5-95a1-5ba8af01bfde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:38984 - \"POST /document/upload HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "await client.post(\n",
    "    document_info[\"url\"],\n",
    "    data=document_info[\"data\"],\n",
    "    files={\"file\": open(path, \"rb\")},\n",
    ")\n",
    "assert response.is_success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec73320-a563-411a-986b-6a8f99e11ed0",
   "metadata": {},
   "source": [
    "The `id` we got back here is used later on to identify the documents that we want to interogate. Let's upload the remaining documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc5c9ac2-1f4b-479a-bfd5-22029d29e198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:38984 - \"GET /document/new?user=Ragna&name=document1.txt HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:38984 - \"POST /document/upload HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:38984 - \"GET /document/new?user=Ragna&name=document2.txt HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:38984 - \"POST /document/upload HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'c8da61cc-0933-43e6-965e-ebdf981fe94b', 'name': 'document0.txt'},\n",
       " {'id': '84a5e2e3-a706-4d04-93d6-4e31d6917efc', 'name': 'document1.txt'},\n",
       " {'id': 'e13655f0-99b0-4f0b-8ba5-95f05d674617', 'name': 'document2.txt'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [document]\n",
    "\n",
    "for path in paths[1:]:\n",
    "    document_info = (\n",
    "        await client.get(\n",
    "            f\"{URL}/document/new\", params={\"user\": USER, \"name\": path.name}\n",
    "        )\n",
    "    ).json()\n",
    "    documents.append(document_info[\"document\"])\n",
    "    await client.post(\n",
    "        document_info[\"url\"],\n",
    "        data=document_info[\"data\"],\n",
    "        files={\"file\": open(path, \"rb\")},\n",
    "    )\n",
    "\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7492b159-f00d-43d4-88f0-3ac789805674",
   "metadata": {},
   "source": [
    "Finally, we can create a new chat with the documents that we have uploaded as well as the source storage and assistant that we selected earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce27d767-db05-444c-854f-3b0aef34824c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:38984 - \"POST /chat/new?user=Ragna HTTP/1.1\" 200 OK\n",
      "{'closed': False,\n",
      " 'id': '07340622-9c3a-467c-8c54-b61bac48ee65',\n",
      " 'messages': [],\n",
      " 'metadata': {'assistant': 'Ragna/DemoAssistant',\n",
      "              'document_ids': ['c8da61cc-0933-43e6-965e-ebdf981fe94b',\n",
      "                               '84a5e2e3-a706-4d04-93d6-4e31d6917efc',\n",
      "                               'e13655f0-99b0-4f0b-8ba5-95f05d674617'],\n",
      "              'name': 'Ragna REST API example',\n",
      "              'params': {},\n",
      "              'source_storage': 'Ragna/DemoSourceStorage'},\n",
      " 'started': False}\n"
     ]
    }
   ],
   "source": [
    "response = await client.post(\n",
    "    f\"{URL}/chat/new\",\n",
    "    params={\"user\": USER},\n",
    "    json={\n",
    "        \"name\": \"Ragna REST API example\",\n",
    "        \"document_ids\": [d[\"id\"] for d in documents],\n",
    "        \"source_storage\": SOURCE_STORAGE,\n",
    "        \"assistant\": ASSISTANT,\n",
    "    },\n",
    ")\n",
    "chat = response.json()\n",
    "pprint(chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b74f96-3e02-4a70-8d54-c34d73f706bd",
   "metadata": {},
   "source": [
    "As indicated by the `'started': False` in the response, we need to start our chat before we can start the interogation. In this step we extract the data out of the uploaded documents and store them in our source storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c29b098-5a7c-46f2-86d2-8957dbb25047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:38984 - \"POST /chat/07340622-9c3a-467c-8c54-b61bac48ee65/start?user=Ragna HTTP/1.1\" 200 OK\n",
      "{'closed': False,\n",
      " 'id': '07340622-9c3a-467c-8c54-b61bac48ee65',\n",
      " 'messages': [{'content': 'How can I help you with the documents?',\n",
      "               'id': '679c7036-9f49-4a60-b7e2-30a52619b55e',\n",
      "               'role': 'system',\n",
      "               'sources': []}],\n",
      " 'metadata': {'assistant': 'Ragna/DemoAssistant',\n",
      "              'document_ids': ['84a5e2e3-a706-4d04-93d6-4e31d6917efc',\n",
      "                               'c8da61cc-0933-43e6-965e-ebdf981fe94b',\n",
      "                               'e13655f0-99b0-4f0b-8ba5-95f05d674617'],\n",
      "              'name': 'Ragna REST API example',\n",
      "              'params': {},\n",
      "              'source_storage': 'Ragna/DemoSourceStorage'},\n",
      " 'started': True}\n"
     ]
    }
   ],
   "source": [
    "CHAT_ID = chat[\"id\"]\n",
    "\n",
    "response = await client.post(f\"{URL}/chat/{CHAT_ID}/start\", params={\"user\": USER})\n",
    "chat = response.json()\n",
    "pprint(chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cda4f0-3943-43f3-9d6c-a123f3101496",
   "metadata": {},
   "source": [
    "With that out of the way, we can now request answers to our prompts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bf0c0fe-64f9-40d6-b1c7-bd9b17e859d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:38984 - \"POST /chat/07340622-9c3a-467c-8c54-b61bac48ee65/answer?user=Ragna&prompt=What%20is%20Ragna%3F HTTP/1.1\" 200 OK\n",
      "{'content': \"I just pretend to be an LLM. I can't actually help with your \"\n",
      "            'prompt:\\n'\n",
      "            '\\n'\n",
      "            '> What is Ragna?\\n'\n",
      "            '\\n'\n",
      "            'I was given the following sources:\\n'\n",
      "            '\\n'\n",
      "            '- document1.txt: This is content of document 1\\n'\n",
      "            '- document0.txt: This is content of document 0\\n'\n",
      "            '- document2.txt: This is content of document 2',\n",
      " 'id': '0d713ff5-72c5-42d6-8cc4-33dc38b6e6ae',\n",
      " 'role': 'assistant',\n",
      " 'sources': [{'document_id': '84a5e2e3-a706-4d04-93d6-4e31d6917efc',\n",
      "              'document_name': 'document1.txt',\n",
      "              'location': ''},\n",
      "             {'document_id': 'c8da61cc-0933-43e6-965e-ebdf981fe94b',\n",
      "              'document_name': 'document0.txt',\n",
      "              'location': ''},\n",
      "             {'document_id': 'e13655f0-99b0-4f0b-8ba5-95f05d674617',\n",
      "              'document_name': 'document2.txt',\n",
      "              'location': ''}]}\n",
      "I just pretend to be an LLM. I can't actually help with your prompt:\n",
      "\n",
      "> What is Ragna?\n",
      "\n",
      "I was given the following sources:\n",
      "\n",
      "- document1.txt: This is content of document 1\n",
      "- document0.txt: This is content of document 0\n",
      "- document2.txt: This is content of document 2\n"
     ]
    }
   ],
   "source": [
    "response = await client.post(\n",
    "    f\"{URL}/chat/{CHAT_ID}/answer\", params={\"user\": USER, \"prompt\": \"What is Ragna?\"}\n",
    ")\n",
    "answer = response.json()\n",
    "pprint(answer[\"message\"])\n",
    "print(answer[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38071c7b-13a7-49c5-84f5-e8f1d205d578",
   "metadata": {},
   "source": [
    "Welp, that was not really helpful, but unfortunately, this is the reality for the demo components we selected. Select some more elaborate components and you will get better answers. We could keep keep requesting answers, but at some point, the user likely wants to close the chat and move on. Doing so will prevent any further questions to be asked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f021fe9b-ae71-4101-aa18-22277ebab8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:38984 - \"POST /chat/07340622-9c3a-467c-8c54-b61bac48ee65/close?user=Ragna HTTP/1.1\" 200 OK\n",
      "{'closed': True,\n",
      " 'id': '07340622-9c3a-467c-8c54-b61bac48ee65',\n",
      " 'messages': [{'content': 'How can I help you with the documents?',\n",
      "               'id': '679c7036-9f49-4a60-b7e2-30a52619b55e',\n",
      "               'role': 'system',\n",
      "               'sources': []},\n",
      "              {'content': 'What is Ragna?',\n",
      "               'id': 'edd7273b-2fbc-4d40-8b82-ce4b29805430',\n",
      "               'role': 'user',\n",
      "               'sources': []},\n",
      "              {'content': \"I just pretend to be an LLM. I can't actually help \"\n",
      "                          'with your prompt:\\n'\n",
      "                          '\\n'\n",
      "                          '> What is Ragna?\\n'\n",
      "                          '\\n'\n",
      "                          'I was given the following sources:\\n'\n",
      "                          '\\n'\n",
      "                          '- document1.txt: This is content of document 1\\n'\n",
      "                          '- document0.txt: This is content of document 0\\n'\n",
      "                          '- document2.txt: This is content of document 2',\n",
      "               'id': '0d713ff5-72c5-42d6-8cc4-33dc38b6e6ae',\n",
      "               'role': 'assistant',\n",
      "               'sources': [{'document_id': '84a5e2e3-a706-4d04-93d6-4e31d6917efc',\n",
      "                            'document_name': 'document1.txt',\n",
      "                            'location': ''},\n",
      "                           {'document_id': 'c8da61cc-0933-43e6-965e-ebdf981fe94b',\n",
      "                            'document_name': 'document0.txt',\n",
      "                            'location': ''},\n",
      "                           {'document_id': 'e13655f0-99b0-4f0b-8ba5-95f05d674617',\n",
      "                            'document_name': 'document2.txt',\n",
      "                            'location': ''}]}],\n",
      " 'metadata': {'assistant': 'Ragna/DemoAssistant',\n",
      "              'document_ids': ['84a5e2e3-a706-4d04-93d6-4e31d6917efc',\n",
      "                               'c8da61cc-0933-43e6-965e-ebdf981fe94b',\n",
      "                               'e13655f0-99b0-4f0b-8ba5-95f05d674617'],\n",
      "              'name': 'Ragna REST API example',\n",
      "              'params': {},\n",
      "              'source_storage': 'Ragna/DemoSourceStorage'},\n",
      " 'started': True}\n"
     ]
    }
   ],
   "source": [
    "response = await client.post(f\"{URL}/chat/{CHAT_ID}/close\", params={\"user\": USER})\n",
    "chat = response.json()\n",
    "pprint(chat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
