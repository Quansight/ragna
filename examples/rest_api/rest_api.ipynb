{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8f335a3-b143-4f8c-bcfd-31f992880464",
   "metadata": {},
   "source": [
    "We start the REST API in the background and wait for it to come up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f6e29a8-0bc0-4988-8e30-7da332d21f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "platform/c++/implementation/internal.cpp:205:reinit_singlethreaded(): Reinitialising as single-threaded.\n",
      "platform/c++/implementation/internal.cpp:205:reinit_singlethreaded(): Reinitialising as single-threaded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:34064 - \"GET / HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [68894]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:31476 (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "import httpx\n",
    "\n",
    "from ragna import Config\n",
    "\n",
    "config = Config.demo()\n",
    "client = httpx.AsyncClient(base_url=config.api.url)\n",
    "\n",
    "\n",
    "async def start_ragna_api(timeout=30, poll=1):\n",
    "    process = subprocess.Popen([\"ragna\", \"api\", \"--config\", \"demo\"])\n",
    "\n",
    "    start = time.time()\n",
    "    while (time.time() - start) < timeout:\n",
    "        with contextlib.suppress(httpx.ConnectError):\n",
    "            response = await client.get(\"/\")\n",
    "            if response.is_success:\n",
    "                return\n",
    "\n",
    "        try:\n",
    "            process.communicate(timeout=poll)\n",
    "        except subprocess.TimeoutExpired:\n",
    "            # Timeout expiring is good here, because that means the process is still\n",
    "            # running\n",
    "            pass\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    process.kill()\n",
    "    process.communicate()\n",
    "    raise RuntimeError(\"Unable to start ragna api\")\n",
    "\n",
    "\n",
    "await start_ragna_api()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ad4c83-34a8-435f-b606-1e415fc8adb5",
   "metadata": {},
   "source": [
    "A user will have some documents that they want to interogate. Let's create some"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b9f694a-dc07-40e0-8a89-ee26456eae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "paths = []\n",
    "for i in range(3):\n",
    "    path = Path.cwd() / f\"document{i}.txt\"\n",
    "    with open(path, \"w\") as file:\n",
    "        file.write(f\"This is content of document {i}\\n\")\n",
    "    paths.append(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8645f0d-0f4e-4853-8740-6772f4ed4307",
   "metadata": {},
   "source": [
    "Before we start the Rag use case, let's make sure the "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef26a9a-0ee5-4bd5-87ab-e1b90de520f9",
   "metadata": {},
   "source": [
    "We start off by listing all the chats that our user has available. Inside a UI that would happen after login. Since the demo config we used above keeps the state in memory only, unsurprisingly, there are no available chats yets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14f7a094-3687-4027-8b69-b00533741a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:34064 - \"GET /chats?user=Ragna HTTP/1.1\" 200 OK\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "USER = \"Ragna\"\n",
    "\n",
    "response = await client.get(\"/chats\", params={\"user\": USER})\n",
    "pprint(response.json(), sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e3e6e1-1284-4ef0-975a-b8919a8f4df6",
   "metadata": {},
   "source": [
    "Let's check what RAG components are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9126cc0f-2a05-4088-9b98-d281bc5fa4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:34064 - \"GET /components?user=Ragna HTTP/1.1\" 200 OK\n",
      "{'assistants': ['Ragna/DemoAssistant'],\n",
      " 'source_storages': ['Ragna/DemoSourceStorage']}\n"
     ]
    }
   ],
   "source": [
    "response = await client.get(\"/components\", params={\"user\": USER})\n",
    "components = response.json()\n",
    "pprint(components)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6d253c-54fa-4a9b-bc5b-17d2dc9969f5",
   "metadata": {},
   "source": [
    "We pick the demo components for the remainder of this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2635a44-48a2-49dc-80a6-e6d365f1cfd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Ragna/DemoSourceStorage', 'Ragna/DemoAssistant')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SOURCE_STORAGE = components[\"source_storages\"][0]\n",
    "ASSISTANT = components[\"assistants\"][0]\n",
    "\n",
    "SOURCE_STORAGE, ASSISTANT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaa4c94-4ef0-4be5-b350-069ad5691fcf",
   "metadata": {},
   "source": [
    "The document upload is a two-step process. First we request upload info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70e78762-4f6e-45d1-b1ef-38e5403679f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:34064 - \"GET /document?user=Ragna&name=document0.txt HTTP/1.1\" 200 OK\n",
      "{'data': {'token': 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyIjoiUmFnbmEiLCJpZCI6IjJiOThjOTEwLTU5ZGYtNDAzZi04M2ExLTgxNjc0NWFhYTdlYiIsImV4cCI6MTY5NzIxNDA2My4yMjk1NTAxfQ.-DjG1_9d7oXRukuZnV0jrJCS4NPF7f_6DRgqf1Pzagc'},\n",
      " 'document': {'id': '2b98c910-59df-403f-83a1-816745aaa7eb',\n",
      "              'name': 'document0.txt'},\n",
      " 'url': 'http://127.0.0.1:31476/document'}\n"
     ]
    }
   ],
   "source": [
    "path = paths[0]\n",
    "\n",
    "response = await client.get(\"/document\", params={\"user\": USER, \"name\": path.name})\n",
    "document_info = response.json()\n",
    "document = document_info[\"document\"]\n",
    "pprint(document_info, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea79e9bc-ea91-48ac-a68f-64e27ed2f09d",
   "metadata": {},
   "source": [
    "And use this info to perform the actual upload. While this seems unneccessarily complicated here, this is needed to support workflows when we want to upload directly to AWS S3 with presigned URLs. Note that the `token` has a short TTL. By default that is 500 seconds, but is configurable by `Config(upload_token_ttl=...)` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b43b943b-47a8-46a5-95a1-5ba8af01bfde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:34064 - \"POST /document HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "await client.post(\n",
    "    document_info[\"url\"],\n",
    "    data=document_info[\"data\"],\n",
    "    files={\"file\": open(path, \"rb\")},\n",
    ")\n",
    "assert response.is_success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec73320-a563-411a-986b-6a8f99e11ed0",
   "metadata": {},
   "source": [
    "Let's upload the remaining documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc5c9ac2-1f4b-479a-bfd5-22029d29e198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:34064 - \"GET /document?user=Ragna&name=document1.txt HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:34064 - \"POST /document HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:34064 - \"GET /document?user=Ragna&name=document2.txt HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:34064 - \"POST /document HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': '2b98c910-59df-403f-83a1-816745aaa7eb', 'name': 'document0.txt'},\n",
       " {'id': '5bdf9581-d17c-45df-976a-f227187fd016', 'name': 'document1.txt'},\n",
       " {'id': 'bf31b3b0-2204-4ed1-9142-68ffb9970425', 'name': 'document2.txt'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [document]\n",
    "\n",
    "for path in paths[1:]:\n",
    "    document_info = (\n",
    "        await client.get(\"/document\", params={\"user\": USER, \"name\": path.name})\n",
    "    ).json()\n",
    "    documents.append(document_info[\"document\"])\n",
    "    await client.post(\n",
    "        document_info[\"url\"],\n",
    "        data=document_info[\"data\"],\n",
    "        files={\"file\": open(path, \"rb\")},\n",
    "    )\n",
    "\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7492b159-f00d-43d4-88f0-3ac789805674",
   "metadata": {},
   "source": [
    "Finally, we can create a new chat with the documents that we have uploaded as well as the source storage and assistant that we selected earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce27d767-db05-444c-854f-3b0aef34824c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:34064 - \"POST /chats?user=Ragna HTTP/1.1\" 200 OK\n",
      "{'id': '290970f4-a83f-4672-b683-e6bfdfd4f905',\n",
      " 'metadata': {'name': 'Ragna REST API example',\n",
      "              'source_storage': 'Ragna/DemoSourceStorage',\n",
      "              'assistant': 'Ragna/DemoAssistant',\n",
      "              'params': {},\n",
      "              'documents': [{'id': '2b98c910-59df-403f-83a1-816745aaa7eb',\n",
      "                             'name': 'document0.txt'},\n",
      "                            {'id': '5bdf9581-d17c-45df-976a-f227187fd016',\n",
      "                             'name': 'document1.txt'},\n",
      "                            {'id': 'bf31b3b0-2204-4ed1-9142-68ffb9970425',\n",
      "                             'name': 'document2.txt'}]},\n",
      " 'messages': [],\n",
      " 'prepared': False}\n"
     ]
    }
   ],
   "source": [
    "response = await client.post(\n",
    "    \"/chats\",\n",
    "    params={\"user\": USER},\n",
    "    json={\n",
    "        \"name\": \"Ragna REST API example\",\n",
    "        \"documents\": documents,\n",
    "        \"source_storage\": SOURCE_STORAGE,\n",
    "        \"assistant\": ASSISTANT,\n",
    "        \"params\": {},\n",
    "    },\n",
    ")\n",
    "chat = response.json()\n",
    "pprint(chat, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b74f96-3e02-4a70-8d54-c34d73f706bd",
   "metadata": {},
   "source": [
    "As indicated by the `'prepared': False` in the response, we need to prepare our chat before we can start the interogation. In this step we extract the data out of the uploaded documents and store them in our source storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c29b098-5a7c-46f2-86d2-8957dbb25047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:34064 - \"POST /chats/290970f4-a83f-4672-b683-e6bfdfd4f905/prepare?user=Ragna HTTP/1.1\" 200 OK\n",
      "{'message': {'id': 'efaf3601-9860-4b46-a752-c13d146ce65e',\n",
      "             'content': 'How can I help you with the documents?',\n",
      "             'role': 'system',\n",
      "             'sources': [],\n",
      "             'timestamp': '2023-10-13T16:16:04.263443Z'},\n",
      " 'chat': {'id': '290970f4-a83f-4672-b683-e6bfdfd4f905',\n",
      "          'metadata': {'name': 'Ragna REST API example',\n",
      "                       'source_storage': 'Ragna/DemoSourceStorage',\n",
      "                       'assistant': 'Ragna/DemoAssistant',\n",
      "                       'params': {},\n",
      "                       'documents': [{'id': '2b98c910-59df-403f-83a1-816745aaa7eb',\n",
      "                                      'name': 'document0.txt'},\n",
      "                                     {'id': '5bdf9581-d17c-45df-976a-f227187fd016',\n",
      "                                      'name': 'document1.txt'},\n",
      "                                     {'id': 'bf31b3b0-2204-4ed1-9142-68ffb9970425',\n",
      "                                      'name': 'document2.txt'}]},\n",
      "          'messages': [{'id': 'efaf3601-9860-4b46-a752-c13d146ce65e',\n",
      "                        'content': 'How can I help you with the documents?',\n",
      "                        'role': 'system',\n",
      "                        'sources': [],\n",
      "                        'timestamp': '2023-10-13T16:16:04.263443Z'}],\n",
      "          'prepared': True}}\n"
     ]
    }
   ],
   "source": [
    "CHAT_ID = chat[\"id\"]\n",
    "\n",
    "response = await client.post(f\"/chats/{CHAT_ID}/prepare\", params={\"user\": USER})\n",
    "chat = response.json()\n",
    "pprint(chat, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cda4f0-3943-43f3-9d6c-a123f3101496",
   "metadata": {},
   "source": [
    "With that out of the way, we can now request answers to our prompts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bf0c0fe-64f9-40d6-b1c7-bd9b17e859d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:34064 - \"POST /chats/290970f4-a83f-4672-b683-e6bfdfd4f905/answer?user=Ragna&prompt=What%20is%20Ragna%3F HTTP/1.1\" 200 OK\n",
      "{'id': '66d5ff73-3a3c-4fb9-9ecd-3bdbee10250a',\n",
      " 'content': \"I can't really help you with your prompt:\\n\"\n",
      "            '\\n'\n",
      "            '> What is Ragna?\\n'\n",
      "            '\\n'\n",
      "            'I can at least show you the sources that I was given:\\n'\n",
      "            '\\n'\n",
      "            '- document0.txt: This is content of document 0\\n'\n",
      "            '- document1.txt: This is content of document 1\\n'\n",
      "            '- document2.txt: This is content of document 2',\n",
      " 'role': 'assistants',\n",
      " 'sources': [{'id': '53a9fef6-6366-49de-86aa-8d2beb4c6dd6',\n",
      "              'document': {'id': '2b98c910-59df-403f-83a1-816745aaa7eb',\n",
      "                           'name': 'document0.txt'},\n",
      "              'location': ''},\n",
      "             {'id': '632311e4-b065-415a-aa7f-05c2cffd3b53',\n",
      "              'document': {'id': '5bdf9581-d17c-45df-976a-f227187fd016',\n",
      "                           'name': 'document1.txt'},\n",
      "              'location': ''},\n",
      "             {'id': '72bdadde-ab38-4e03-a565-ed9188b91998',\n",
      "              'document': {'id': 'bf31b3b0-2204-4ed1-9142-68ffb9970425',\n",
      "                           'name': 'document2.txt'},\n",
      "              'location': ''}],\n",
      " 'timestamp': '2023-10-13T16:16:04.281448Z'}\n"
     ]
    }
   ],
   "source": [
    "response = await client.post(\n",
    "    f\"/chats/{CHAT_ID}/answer\", params={\"user\": USER, \"prompt\": \"What is Ragna?\"}\n",
    ")\n",
    "answer = response.json()\n",
    "pprint(answer[\"message\"], sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87f84fe0-079d-4c74-8995-4bf1749432ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can't really help you with your prompt:\n",
      "\n",
      "> What is Ragna?\n",
      "\n",
      "I can at least show you the sources that I was given:\n",
      "\n",
      "- document0.txt: This is content of document 0\n",
      "- document1.txt: This is content of document 1\n",
      "- document2.txt: This is content of document 2\n"
     ]
    }
   ],
   "source": [
    "print(answer[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38071c7b-13a7-49c5-84f5-e8f1d205d578",
   "metadata": {},
   "source": [
    "Welp, that was not really helpful, but unfortunately, this is the reality for the demo components we selected. Select some more elaborate components and you will get better answers. We could keep keep requesting answers, but at some point, the user likely wants to delete the chat and move on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d5834d7-b269-4530-a0fe-67b3b3d7bda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:34064 - \"DELETE /chats/290970f4-a83f-4672-b683-e6bfdfd4f905?user=Ragna HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [200 OK]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await client.delete(f\"/chats/{CHAT_ID}\", params={\"user\": USER})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9445d81-8db5-41dd-b11b-ea18f77eb6b5",
   "metadata": {},
   "source": [
    "After the chat is deleted, querying all chats of a user returns an empty list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1a027b3-be97-4364-a0a8-0c3785014f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:34064 - \"GET /chats?user=Ragna HTTP/1.1\" 200 OK\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "response = await client.get(\"/chats\", params={\"user\": USER})\n",
    "chats = response.json()\n",
    "pprint(chats, sort_dicts=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
