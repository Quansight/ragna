{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a30597e-681e-40cb-a414-31926893b9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://127.0.0.1:31476'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragna import demo_config\n",
    "\n",
    "URL = demo_config.ragna_api_url\n",
    "USER = \"Ragna\"\n",
    "\n",
    "URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f335a3-b143-4f8c-bcfd-31f992880464",
   "metadata": {},
   "source": [
    "We start the REST API in the background and wait for it to come up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f6e29a8-0bc0-4988-8e30-7da332d21f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:51472 - \"GET /health HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [19776]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:31476 (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "import httpx\n",
    "\n",
    "proc = subprocess.Popen([\"ragna\", \"api\", \"--config\", \"ragna.demo_config\"])\n",
    "\n",
    "client = httpx.AsyncClient()\n",
    "\n",
    "timeout = 10\n",
    "start = time.time()\n",
    "while (time.time() - start) < timeout:\n",
    "    with contextlib.suppress(httpx.ConnectError):\n",
    "        response = await client.get(f\"{URL}/health\")\n",
    "        if response.is_success:\n",
    "            break\n",
    "\n",
    "    time.sleep(0.5)\n",
    "else:\n",
    "    proc.kill()\n",
    "    stdout, stderr = proc.communicate()\n",
    "    print(stdout)\n",
    "    print(stderr)\n",
    "    raise RuntimeError(\"Unable to start the Ragna REST API\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ad4c83-34a8-435f-b606-1e415fc8adb5",
   "metadata": {},
   "source": [
    "A user will have some documents that they want to interogate. Let's create some"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b9f694a-dc07-40e0-8a89-ee26456eae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "paths = []\n",
    "for i in range(3):\n",
    "    path = Path.cwd() / f\"document{i}.txt\"\n",
    "    with open(path, \"w\") as file:\n",
    "        file.write(f\"This is content of document {i}\\n\")\n",
    "    paths.append(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8645f0d-0f4e-4853-8740-6772f4ed4307",
   "metadata": {},
   "source": [
    "Before we start the Rag use case, let's make sure the "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef26a9a-0ee5-4bd5-87ab-e1b90de520f9",
   "metadata": {},
   "source": [
    "We start off by listing all the chats that our user has available. Inside a UI that would happen after login. Since the demo config we used above keeps the state in memory only, unsurprisingly, there are no available chats yets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14f7a094-3687-4027-8b69-b00533741a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:51472 - \"GET /chats?user=Ragna HTTP/1.1\" 200 OK\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "response = await client.get(f\"{URL}/chats\", params={\"user\": USER})\n",
    "pprint(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e3e6e1-1284-4ef0-975a-b8919a8f4df6",
   "metadata": {},
   "source": [
    "Let's check what RAG components are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9126cc0f-2a05-4088-9b98-d281bc5fa4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:51472 - \"GET /components?user=Ragna HTTP/1.1\" 200 OK\n",
      "{'assistants': ['Ragna/DemoAssistant'],\n",
      " 'source_storages': ['Ragna/DemoSourceStorage']}\n"
     ]
    }
   ],
   "source": [
    "response = await client.get(f\"{URL}/components\", params={\"user\": USER})\n",
    "components = response.json()\n",
    "pprint(components)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6d253c-54fa-4a9b-bc5b-17d2dc9969f5",
   "metadata": {},
   "source": [
    "We pick the demo components for the remainder of this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2635a44-48a2-49dc-80a6-e6d365f1cfd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Ragna/DemoSourceStorage', 'Ragna/DemoAssistant')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SOURCE_STORAGE = components[\"source_storages\"][0]\n",
    "ASSISTANT = components[\"assistants\"][0]\n",
    "\n",
    "SOURCE_STORAGE, ASSISTANT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaa4c94-4ef0-4be5-b350-069ad5691fcf",
   "metadata": {},
   "source": [
    "The document upload is a two-step process. First we request upload info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70e78762-4f6e-45d1-b1ef-38e5403679f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:51472 - \"GET /document/new?user=Ragna&name=document0.txt HTTP/1.1\" 200 OK\n",
      "{'data': {'token': 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyIjoiUmFnbmEiLCJpZCI6IjhiOWQ4MjVhLTQ3OTctNDQxMS1iODc2LWVjM2MxMTM0OThmYyIsImV4cCI6MTY5NjM2Nzk3OS42MjU3MTN9.xT-1YI0awv2hixcHJZaDGqvYP7r8nYFrKB9DygOyHdw'},\n",
      " 'document': {'id': '8b9d825a-4797-4411-b876-ec3c113498fc',\n",
      "              'name': 'document0.txt'},\n",
      " 'url': 'http://127.0.0.1:31476/document/upload'}\n"
     ]
    }
   ],
   "source": [
    "path = paths[0]\n",
    "\n",
    "response = await client.get(\n",
    "    f\"{URL}/document/new\", params={\"user\": USER, \"name\": path.name}\n",
    ")\n",
    "document_info = response.json()\n",
    "document = document_info[\"document\"]\n",
    "pprint(document_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea79e9bc-ea91-48ac-a68f-64e27ed2f09d",
   "metadata": {},
   "source": [
    "And use this info to perform the actual upload. While this seems unneccessarily complicated here, this is needed to support workflows when we want to upload directly to AWS S3 with presigned URLs. Note that the `token` has a short TTL. By default that is 30 seconds, but is configurable by `Config(upload_token_ttl=...)` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b43b943b-47a8-46a5-95a1-5ba8af01bfde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:51472 - \"POST /document/upload HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "await client.post(\n",
    "    document_info[\"url\"],\n",
    "    data=document_info[\"data\"],\n",
    "    files={\"file\": open(path, \"rb\")},\n",
    ")\n",
    "assert response.is_success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec73320-a563-411a-986b-6a8f99e11ed0",
   "metadata": {},
   "source": [
    "The `id` we got back here is used later on to identify the documents that we want to interogate. Let's upload the remaining documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc5c9ac2-1f4b-479a-bfd5-22029d29e198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:51472 - \"GET /document/new?user=Ragna&name=document1.txt HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:51472 - \"POST /document/upload HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:51472 - \"GET /document/new?user=Ragna&name=document2.txt HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:51472 - \"POST /document/upload HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': '8b9d825a-4797-4411-b876-ec3c113498fc', 'name': 'document0.txt'},\n",
       " {'id': '2e0c644b-932b-431e-acd1-623fae885dcc', 'name': 'document1.txt'},\n",
       " {'id': '63fd15fc-2818-4e10-bbb6-d2724e21afc1', 'name': 'document2.txt'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [document]\n",
    "\n",
    "for path in paths[1:]:\n",
    "    document_info = (\n",
    "        await client.get(\n",
    "            f\"{URL}/document/new\", params={\"user\": USER, \"name\": path.name}\n",
    "        )\n",
    "    ).json()\n",
    "    documents.append(document_info[\"document\"])\n",
    "    await client.post(\n",
    "        document_info[\"url\"],\n",
    "        data=document_info[\"data\"],\n",
    "        files={\"file\": open(path, \"rb\")},\n",
    "    )\n",
    "\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7492b159-f00d-43d4-88f0-3ac789805674",
   "metadata": {},
   "source": [
    "Finally, we can create a new chat with the documents that we have uploaded as well as the source storage and assistant that we selected earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce27d767-db05-444c-854f-3b0aef34824c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:51472 - \"POST /chat/new?user=Ragna HTTP/1.1\" 200 OK\n",
      "{'closed': False,\n",
      " 'id': 'c9acfda3-bfc5-422c-835d-09c17ba208aa',\n",
      " 'messages': [],\n",
      " 'metadata': {'assistant': \"<class 'ragna.assistant._demo.RagnaDemoAssistant'>\",\n",
      "              'document_ids': ['8b9d825a-4797-4411-b876-ec3c113498fc',\n",
      "                               '2e0c644b-932b-431e-acd1-623fae885dcc',\n",
      "                               '63fd15fc-2818-4e10-bbb6-d2724e21afc1'],\n",
      "              'name': 'Ragna REST API example',\n",
      "              'params': {},\n",
      "              'source_storage': '<class '\n",
      "                                \"'ragna.source_storage._demo.RagnaDemoSourceStorage'>\"},\n",
      " 'started': False}\n"
     ]
    }
   ],
   "source": [
    "response = await client.post(\n",
    "    f\"{URL}/chat/new\",\n",
    "    params={\"user\": USER},\n",
    "    json={\n",
    "        \"name\": \"Ragna REST API example\",\n",
    "        \"document_ids\": [d[\"id\"] for d in documents],\n",
    "        \"source_storage\": SOURCE_STORAGE,\n",
    "        \"assistant\": ASSISTANT,\n",
    "    },\n",
    ")\n",
    "chat = response.json()\n",
    "pprint(chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b74f96-3e02-4a70-8d54-c34d73f706bd",
   "metadata": {},
   "source": [
    "As indicated by the `'started': False` in the response, we need to start our chat before we can start the interogation. In this step we extract the data out of the uploaded documents and store them in our source storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c29b098-5a7c-46f2-86d2-8957dbb25047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:51472 - \"POST /chat/c9acfda3-bfc5-422c-835d-09c17ba208aa/start?user=Ragna HTTP/1.1\" 500 Internal Server Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/philip/.conda/envs/ragna-dev/lib/python3.9/site-packages/uvicorn/protocols/http/httptools_impl.py\", line 426, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "  File \"/home/philip/.conda/envs/ragna-dev/lib/python3.9/site-packages/uvicorn/middleware/proxy_headers.py\", line 84, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "  File \"/home/philip/.conda/envs/ragna-dev/lib/python3.9/site-packages/fastapi/applications.py\", line 290, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"/home/philip/.conda/envs/ragna-dev/lib/python3.9/site-packages/starlette/applications.py\", line 122, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"/home/philip/.conda/envs/ragna-dev/lib/python3.9/site-packages/starlette/middleware/errors.py\", line 184, in __call__\n",
      "    raise exc\n",
      "  File \"/home/philip/.conda/envs/ragna-dev/lib/python3.9/site-packages/starlette/middleware/errors.py\", line 162, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"/home/philip/.conda/envs/ragna-dev/lib/python3.9/site-packages/starlette/middleware/exceptions.py\", line 79, in __call__\n",
      "    raise exc\n",
      "  File \"/home/philip/.conda/envs/ragna-dev/lib/python3.9/site-packages/starlette/middleware/exceptions.py\", line 68, in __call__\n",
      "    await self.app(scope, receive, sender)\n",
      "  File \"/home/philip/.conda/envs/ragna-dev/lib/python3.9/site-packages/fastapi/middleware/asyncexitstack.py\", line 20, in __call__\n",
      "    raise e\n",
      "  File \"/home/philip/.conda/envs/ragna-dev/lib/python3.9/site-packages/fastapi/middleware/asyncexitstack.py\", line 17, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"/home/philip/.conda/envs/ragna-dev/lib/python3.9/site-packages/starlette/routing.py\", line 718, in __call__\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"/home/philip/.conda/envs/ragna-dev/lib/python3.9/site-packages/starlette/routing.py\", line 276, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"/home/philip/.conda/envs/ragna-dev/lib/python3.9/site-packages/starlette/routing.py\", line 66, in app\n",
      "    response = await func(request)\n",
      "  File \"/home/philip/.conda/envs/ragna-dev/lib/python3.9/site-packages/fastapi/routing.py\", line 231, in app\n",
      "    solved_result = await solve_dependencies(\n",
      "  File \"/home/philip/.conda/envs/ragna-dev/lib/python3.9/site-packages/fastapi/dependencies/utils.py\", line 622, in solve_dependencies\n",
      "    solved = await call(**sub_values)\n",
      "  File \"/home/philip/git/ora/ragna/_api.py\", line 220, in _get_chat\n",
      "    return rag._get_chat(user=user, id=id)\n",
      "  File \"/home/philip/git/ora/ragna/core/_rag.py\", line 174, in _get_chat\n",
      "    self._get_chats(user=user)\n",
      "  File \"/home/philip/git/ora/ragna/core/_rag.py\", line 123, in _get_chats\n",
      "    chats = [\n",
      "  File \"/home/philip/git/ora/ragna/core/_rag.py\", line 137, in <listcomp>\n",
      "    source_storage=self._parse_component(\n",
      "AttributeError: 'Rag' object has no attribute '_parse_component'\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m CHAT_ID \u001b[38;5;241m=\u001b[39m chat[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m client\u001b[38;5;241m.\u001b[39mpost(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mURL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/chat/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCHAT_ID\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/start\u001b[39m\u001b[38;5;124m\"\u001b[39m, params\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: USER})\n\u001b[0;32m----> 4\u001b[0m chat \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m pprint(chat)\n",
      "File \u001b[0;32m~/.conda/envs/ragna-dev/lib/python3.9/site-packages/httpx/_models.py:756\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    754\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m jsonlib\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mdecode(encoding), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 756\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjsonlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/ragna-dev/lib/python3.9/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/.conda/envs/ragna-dev/lib/python3.9/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/.conda/envs/ragna-dev/lib/python3.9/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "CHAT_ID = chat[\"id\"]\n",
    "\n",
    "response = await client.post(f\"{URL}/chat/{CHAT_ID}/start\", params={\"user\": USER})\n",
    "chat = response.json()\n",
    "pprint(chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cda4f0-3943-43f3-9d6c-a123f3101496",
   "metadata": {},
   "source": [
    "With that out of the way, we can now request answers to our prompts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf0c0fe-64f9-40d6-b1c7-bd9b17e859d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await client.post(\n",
    "    f\"{URL}/chat/{CHAT_ID}/answer\", params={\"user\": USER, \"prompt\": \"What is Ragna?\"}\n",
    ")\n",
    "answer = response.json()\n",
    "pprint(answer[\"message\"])\n",
    "print(answer[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38071c7b-13a7-49c5-84f5-e8f1d205d578",
   "metadata": {},
   "source": [
    "Welp, that was not really helpful, but unfortunately, this is the reality for the demo components we selected. Select some more elaborate components and you will get better answers. We could keep keep requesting answers, but at some point, the user likely wants to close the chat and move on. Doing so will prevent any further questions to be asked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f021fe9b-ae71-4101-aa18-22277ebab8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await client.post(f\"{URL}/chat/{CHAT_ID}/close\", params={\"user\": USER})\n",
    "chat = response.json()\n",
    "pprint(chat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
