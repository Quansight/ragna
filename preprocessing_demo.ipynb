{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "192e7b22-47c8-41f5-ae1b-f63b0ac5131d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27a0556d-5fa3-48aa-94df-ee5b916ebcdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/andrew/.dropbox-hm/Dropbox/quansight/dev/ragna/ragna/docs/install.md'),\n",
       " PosixPath('/home/andrew/.dropbox-hm/Dropbox/quansight/dev/ragna/ragna/docs/index.md'),\n",
       " PosixPath('/home/andrew/.dropbox-hm/Dropbox/quansight/dev/ragna/ragna/docs/community/welcome.md'),\n",
       " PosixPath('/home/andrew/.dropbox-hm/Dropbox/quansight/dev/ragna/ragna/docs/community/contribute.md'),\n",
       " PosixPath('/home/andrew/.dropbox-hm/Dropbox/quansight/dev/ragna/ragna/docs/explanations/what-is-rag.md'),\n",
       " PosixPath('/home/andrew/.dropbox-hm/Dropbox/quansight/dev/ragna/ragna/docs/examples/README.md'),\n",
       " PosixPath('/home/andrew/.dropbox-hm/Dropbox/quansight/dev/ragna/ragna/docs/references/python-api.md'),\n",
       " PosixPath('/home/andrew/.dropbox-hm/Dropbox/quansight/dev/ragna/ragna/docs/references/deploy.md'),\n",
       " PosixPath('/home/andrew/.dropbox-hm/Dropbox/quansight/dev/ragna/ragna/docs/references/config.md'),\n",
       " PosixPath('/home/andrew/.dropbox-hm/Dropbox/quansight/dev/ragna/ragna/docs/references/release-notes.md'),\n",
       " PosixPath('/home/andrew/.dropbox-hm/Dropbox/quansight/dev/ragna/ragna/docs/references/faq.md'),\n",
       " PosixPath('/home/andrew/.dropbox-hm/Dropbox/quansight/dev/ragna/ragna/docs/tutorials/README.md')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "docs_path = Path.cwd().joinpath(\"docs\")\n",
    "\n",
    "md_files = list(docs_path.glob(\"**/*.md\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c2c65be-03fb-45dd-b9a2-4c9684e09b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.59.7-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/andrew/micromamba/envs/ragna-dev/lib/python3.10/site-packages (from openai) (4.8.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/andrew/micromamba/envs/ragna-dev/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/andrew/micromamba/envs/ragna-dev/lib/python3.10/site-packages (from openai) (2.10.5)\n",
      "Requirement already satisfied: sniffio in /home/andrew/micromamba/envs/ragna-dev/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/andrew/micromamba/envs/ragna-dev/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/andrew/micromamba/envs/ragna-dev/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/andrew/micromamba/envs/ragna-dev/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/andrew/micromamba/envs/ragna-dev/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /home/andrew/micromamba/envs/ragna-dev/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /home/andrew/micromamba/envs/ragna-dev/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/andrew/micromamba/envs/ragna-dev/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/andrew/micromamba/envs/ragna-dev/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/andrew/micromamba/envs/ragna-dev/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Downloading openai-1.59.7-py3-none-any.whl (454 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
      "Installing collected packages: jiter, distro, openai\n",
      "Successfully installed distro-1.9.0 jiter-0.8.2 openai-1.59.7\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7646cdb-fadc-4e57-ad96-05532a211bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm just a program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# openai work\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "def stream_openai(client, role, message):\n",
    "    stream = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": role, \"content\": message}],\n",
    "        stream=True,\n",
    "    )\n",
    "    message = \"\"\n",
    "    for chunk in stream:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            message += chunk.choices[0].delta.content\n",
    "    return message\n",
    "\n",
    "m = stream_openai(client, \"user\", \"hello, how are you?\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "861713ce-bb5f-484b-b7e3-e96b9b8775ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from ragna.source_storages import RagnaDemoSourceStorage\n",
    "from ragna.assistants import RagnaDemoAssistant\n",
    "from ragna.preprocessors import RagnaDemoPreprocessor\n",
    "from ragna import Rag\n",
    "from ragna.core import (\n",
    "    LocalDocument, Document, QueryPreprocessor, MetadataFilter, ProcessedQuery\n",
    ")\n",
    "from ragna.assistants import Gpt4\n",
    "\n",
    "\n",
    "\n",
    "storage = RagnaDemoSourceStorage()\n",
    "\n",
    "documents = [\n",
    "            (\n",
    "                document\n",
    "                if isinstance(document, Document)\n",
    "                else LocalDocument.from_path(document)\n",
    "            )\n",
    "            for document in md_files\n",
    "        ]\n",
    "storage.store(\"ragna_docs\", documents)\n",
    "\n",
    "\n",
    "class TestPreprocessor(QueryPreprocessor):\n",
    "\n",
    "    def __init__(self):\n",
    "        # self.storage=storage\n",
    "        # self.assistant=assistant\n",
    "        self.messages = []\n",
    "\n",
    "    def ask_assistant(self, prompt):\n",
    "        instruction = (\"take the following prompt and \"\n",
    "                       \"improve it so that it will be \"\n",
    "                       \"better for querying a database: \" + prompt)\n",
    "        \n",
    "        assistant_answer = stream_openai(client, \"user\", instruction)\n",
    "        return assistant_answer\n",
    "\n",
    "    def process(self, query: str, metadata_filter: Optional[MetadataFilter]):\n",
    "        processed_query = self.ask_assistant(query)\n",
    "        return ProcessedQuery(\n",
    "            original_query=query,\n",
    "            processed_query=processed_query,\n",
    "            metadata_filter=None,\n",
    "            processor_name=self.display_name()\n",
    "        )\n",
    "\n",
    "\n",
    "chat = Rag().chat(\n",
    "    input=None,\n",
    "    source_storage = storage,\n",
    "    assistant=RagnaDemoAssistant,\n",
    "    preprocessor=TestPreprocessor,\n",
    "    corpus_name=\"ragna_docs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0966f19-a524-49ce-9769-75e486231c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = await chat.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a9af3eb-5efe-4d17-875d-5480f928c94d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm a demo assistant and can be used to try Ragna's workflow.\n",
      "I will only mirror back my inputs. \n",
      "\n",
      "So far I have received 1 messages.\n",
      "\n",
      "Your last prompt was:\n",
      "\n",
      "> To improve the prompt for querying a database, it's important to specify the context, the type of events you're interested in, and any relevant parameters. Hereâ€™s a refined version:\n",
      "\n",
      "\"Can you provide a summary of significant events that occurred in the year 2022, including their dates, locations, and categories (e.g., economic, social, political, or environmental)?\"\n",
      "\n",
      "This version clarifies the timeframe and the specific details you want to obtain, which will facilitate more accurate database queries.\n",
      "\n",
      "These are the sources I was given:\n",
      "\n",
      "- install.md: # Installation ## Prerequisites You need Python 3.9 or above in your working environment to [...]\n",
      "- index.md: --- title: Home --- # Ragna â€” Open source RAG orchestration framework With an intuitive API [...]\n",
      "- welcome.md: # Welcome! Thanks for participating in the Ragna community! As an early-stage open source [...]\n",
      "- contribute.md: # Contribution guidelines Thanks for your interest in contributing to Ragna! All Ragna [...]\n",
      "- what-is-rag.md: # What is RAG? !!! tip \"Under development\" This documentation page is being actively worked [...]\n",
      "- README.md: ## Examples\n",
      "- python-api.md: # Python API reference ::: ragna.local_root ::: ragna.core ::: ragna.source_storages ::: [...]\n",
      "- deploy.md: # REST API reference <!-- Generated using assets/openapi.json - a copy of the autogenerated [...]\n",
      "- config.md: # Configuration reference Ragna uses [TOML](https://toml.io/en/) as language for its [...]\n",
      "- release-notes.md: # Release notes ## Version 0.2.0 ### Feature changes and enhancements - Ragna's `0.1.x` [...]\n",
      "- faq.md: # Frequently asked questions ## Why should I use Ragna and not X? !!! tip \"TL;DR\" Ragna is the [...]\n",
      "- README.md: ## Tutorials\n",
      "[...]\n"
     ]
    }
   ],
   "source": [
    "print(await chat.answer(\"What happened last year?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85129b4-e087-4de7-9d30-a23f0f849f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aebb98-a054-4528-967a-d46dbd96bcfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
