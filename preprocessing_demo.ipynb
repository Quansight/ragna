{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "192e7b22-47c8-41f5-ae1b-f63b0ac5131d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27a0556d-5fa3-48aa-94df-ee5b916ebcdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/andrew/.dropbox-hm/Dropbox/quansight/dev/ragna/ragna/docs/install.md'),\n",
       " PosixPath('/home/andrew/.dropbox-hm/Dropbox/quansight/dev/ragna/ragna/docs/index.md'),\n",
       " PosixPath('/home/andrew/.dropbox-hm/Dropbox/quansight/dev/ragna/ragna/docs/community/welcome.md'),\n",
       " PosixPath('/home/andrew/.dropbox-hm/Dropbox/quansight/dev/ragna/ragna/docs/community/contribute.md'),\n",
       " PosixPath('/home/andrew/.dropbox-hm/Dropbox/quansight/dev/ragna/ragna/docs/explanations/what-is-rag.md'),\n",
       " PosixPath('/home/andrew/.dropbox-hm/Dropbox/quansight/dev/ragna/ragna/docs/examples/README.md'),\n",
       " PosixPath('/home/andrew/.dropbox-hm/Dropbox/quansight/dev/ragna/ragna/docs/references/python-api.md'),\n",
       " PosixPath('/home/andrew/.dropbox-hm/Dropbox/quansight/dev/ragna/ragna/docs/references/deploy.md'),\n",
       " PosixPath('/home/andrew/.dropbox-hm/Dropbox/quansight/dev/ragna/ragna/docs/references/config.md'),\n",
       " PosixPath('/home/andrew/.dropbox-hm/Dropbox/quansight/dev/ragna/ragna/docs/references/release-notes.md'),\n",
       " PosixPath('/home/andrew/.dropbox-hm/Dropbox/quansight/dev/ragna/ragna/docs/references/faq.md'),\n",
       " PosixPath('/home/andrew/.dropbox-hm/Dropbox/quansight/dev/ragna/ragna/docs/tutorials/README.md')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "docs_path = Path.cwd().joinpath(\"docs\")\n",
    "\n",
    "md_files = list(docs_path.glob(\"**/*.md\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7646cdb-fadc-4e57-ad96-05532a211bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm just a program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# openai work\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "def stream_openai(client, role, message):\n",
    "    stream = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": role, \"content\": message}],\n",
    "        stream=True,\n",
    "    )\n",
    "    message = \"\"\n",
    "    for chunk in stream:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            message += chunk.choices[0].delta.content\n",
    "    return message\n",
    "\n",
    "m = stream_openai(client, \"user\", \"hello, how are you?\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "861713ce-bb5f-484b-b7e3-e96b9b8775ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from ragna.source_storages import RagnaDemoSourceStorage\n",
    "from ragna.assistants import RagnaDemoAssistant\n",
    "from ragna.preprocessors import RagnaDemoPreprocessor\n",
    "from ragna import Rag\n",
    "from ragna.core import (\n",
    "    LocalDocument, Document, QueryPreprocessor, MetadataFilter, ProcessedQuery\n",
    ")\n",
    "from ragna.assistants import Gpt4\n",
    "\n",
    "\n",
    "\n",
    "storage = RagnaDemoSourceStorage()\n",
    "\n",
    "documents = [\n",
    "            (\n",
    "                document\n",
    "                if isinstance(document, Document)\n",
    "                else LocalDocument.from_path(document)\n",
    "            )\n",
    "            for document in md_files\n",
    "        ]\n",
    "storage.store(\"ragna_docs\", documents)\n",
    "\n",
    "\n",
    "class TestPreprocessor(QueryPreprocessor):\n",
    "\n",
    "    def __init__(self):\n",
    "        # self.storage=storage\n",
    "        # self.assistant=assistant\n",
    "        self.messages = []\n",
    "\n",
    "    def ask_assistant(self, prompt):\n",
    "        instruction = (\"take the following prompt and \"\n",
    "                       \"improve it so that it will be \"\n",
    "                       \"better for querying a database. \"\n",
    "                       \"Only give the reformatted prompt. \"\n",
    "                       \"do not give any other context.: \" + prompt)\n",
    "        \n",
    "        assistant_answer = stream_openai(client, \"user\", instruction)\n",
    "        return assistant_answer\n",
    "\n",
    "    def process(self, query: str, metadata_filter: Optional[MetadataFilter]):\n",
    "        processed_query = self.ask_assistant(query)\n",
    "        return ProcessedQuery(\n",
    "            original_query=query,\n",
    "            processed_query=processed_query,\n",
    "            metadata_filter=None,\n",
    "            processor_name=self.display_name()\n",
    "        )\n",
    "\n",
    "\n",
    "chat = Rag().chat(\n",
    "    input=None,\n",
    "    source_storage = storage,\n",
    "    assistant=RagnaDemoAssistant,\n",
    "    preprocessor=TestPreprocessor,\n",
    "    corpus_name=\"ragna_docs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0966f19-a524-49ce-9769-75e486231c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = await chat.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a9af3eb-5efe-4d17-875d-5480f928c94d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm a demo assistant and can be used to try Ragna's workflow.\n",
      "I will only mirror back my inputs. \n",
      "\n",
      "So far I have received 1 messages.\n",
      "\n",
      "Your last prompt was:\n",
      "\n",
      "> What events or occurrences took place in the year 2022?\n",
      "\n",
      "These are the sources I was given:\n",
      "\n",
      "- install.md: # Installation ## Prerequisites You need Python 3.9 or above in your working environment to [...]\n",
      "- index.md: --- title: Home --- # Ragna â€” Open source RAG orchestration framework With an intuitive API [...]\n",
      "- welcome.md: # Welcome! Thanks for participating in the Ragna community! As an early-stage open source [...]\n",
      "- contribute.md: # Contribution guidelines Thanks for your interest in contributing to Ragna! All Ragna [...]\n",
      "- what-is-rag.md: # What is RAG? !!! tip \"Under development\" This documentation page is being actively worked [...]\n",
      "- README.md: ## Examples\n",
      "- python-api.md: # Python API reference ::: ragna.local_root ::: ragna.core ::: ragna.source_storages ::: [...]\n",
      "- deploy.md: # REST API reference <!-- Generated using assets/openapi.json - a copy of the autogenerated [...]\n",
      "- config.md: # Configuration reference Ragna uses [TOML](https://toml.io/en/) as language for its [...]\n",
      "- release-notes.md: # Release notes ## Version 0.2.0 ### Feature changes and enhancements - Ragna's `0.1.x` [...]\n",
      "- faq.md: # Frequently asked questions ## Why should I use Ragna and not X? !!! tip \"TL;DR\" Ragna is the [...]\n",
      "- README.md: ## Tutorials\n",
      "[...]\n"
     ]
    }
   ],
   "source": [
    "print(await chat.answer(\"What happened last year?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85129b4-e087-4de7-9d30-a23f0f849f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aebb98-a054-4528-967a-d46dbd96bcfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
